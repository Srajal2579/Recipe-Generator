{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a6e047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Install Dependencies\n",
    "!pip install pandas scikit-learn joblib nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53263927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Imports & Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords') \n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "english_stop_words = set(stopwords.words('english'))\n",
    "custom_recipe_stop_words = {\n",
    "    'fresh', 'dry', 'frozen', 'cup', 'ounce', 'pound', 'tablespoon', 'teaspoon', \n",
    "    'clove', 'package', 'can', 'jar', 'diced', 'chopped', 'minced', 'sliced', \n",
    "    'pinch', 'large', 'small', 'medium', 'container', 'dash', 'serving', 'to', \n",
    "    'oz', 'tbsp', 'tsp', 'g', 'kg', 'ml', 'l', 'of', 'and', 'with', 'or', 'taste'\n",
    "}\n",
    "ALL_STOP_WORDS = english_stop_words.union(custom_recipe_stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275379cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load Dataset\n",
    "# Ensure 'recipes.csv' is uploaded to your environment\n",
    "df = pd.read_csv(r\"backend\\data\\recipes.csv\")\n",
    "\n",
    "# Create a simplified 'cuisine' column from the path (e.g., \"/Desserts/Pies/\" -> \"Desserts\")\n",
    "def extract_cuisine(path):\n",
    "    if pd.isna(path): return \"Unknown\"\n",
    "    parts = [p for p in path.strip(\"/\").split(\"/\") if p]\n",
    "    if parts:\n",
    "        return parts[0] # Take the top-level category\n",
    "    return \"General\"\n",
    "\n",
    "df['cuisine'] = df['cuisine_path'].apply(extract_cuisine)\n",
    "\n",
    "# Fill missing values\n",
    "df['recipe_name'] = df['recipe_name'].fillna(\"Untitled Recipe\")\n",
    "df['ingredients'] = df['ingredients'].fillna(\"\")\n",
    "\n",
    "print(f\"Loaded {len(df)} recipes.\")\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6316823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Preprocess Ingredients\n",
    "\n",
    "def clean_ingredient_text(text: str) -> str:\n",
    "    \"\"\"Cleans a full string of ingredients.\"\"\"\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove non-alphabet characters (keep spaces)\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Tokenize & Lemmatize\n",
    "    words = []\n",
    "    for w in text.split():\n",
    "        if w not in ALL_STOP_WORDS and len(w) > 2: # filtering short noise words\n",
    "            words.append(lemmatizer.lemmatize(w))\n",
    "    \n",
    "    return \" \".join(words)\n",
    "\n",
    "# Apply cleaning\n",
    "df[\"clean_ings_str\"] = df[\"ingredients\"].apply(clean_ingredient_text)\n",
    "\n",
    "print(\"\\n--- Sample Preprocessing ---\")\n",
    "print(f\"Original: {df.loc[0, 'ingredients'][:100]}...\")\n",
    "print(f\"Cleaned:  {df.loc[0, 'clean_ings_str'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9447764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Vectorize Recipes\n",
    "vectorizer = TfidfVectorizer(max_features=5000) # Limit features to keep model size manageable\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"clean_ings_str\"])\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fc5962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Save Model Artifacts\n",
    "# We save 'recipe_name' as the title, and keep 'ingredients' for display.\n",
    "\n",
    "# 1. Save Cleaned Data (CSV)\n",
    "# We rename 'recipe_name' to 'title' for consistency in the app\n",
    "save_df = df.rename(columns={'recipe_name': 'title'})\n",
    "save_df = save_df[[\"title\", \"cuisine\", \"ingredients\", \"clean_ings_str\", \"url\", \"img_src\"]]\n",
    "save_df.to_csv(\"cleaned_recipes.csv\", index=False)\n",
    "print(\"Saved cleaned_recipes.csv\")\n",
    "\n",
    "# 2. Save Artifacts for Backend\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
    "joblib.dump(tfidf_matrix, \"recipe_vectors.pkl\")\n",
    "\n",
    "# Save metadata list (dictionaries are faster to load/iterate in the app)\n",
    "metadata = save_df.to_dict(orient=\"records\")\n",
    "joblib.dump(metadata, \"recipes_metadata.pkl\")\n",
    "\n",
    "print(\"All artifacts saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
